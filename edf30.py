import os
import re
from datetime import datetime
from collections import Counter
import json
import mne
import numpy as np
from scipy import signal

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∞–Ω–∞–ª–∏–∑–∞
ANALYSIS_CONFIG = {
	# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –≠–ö–ì –∞–Ω–∞–ª–∏–∑–∞
	'ecg': {
		'tachycardia_threshold': 100,  # –ø–æ—Ä–æ–≥ —Ç–∞—Ö–∏–∫–∞—Ä–¥–∏–∏ (—É–¥/–º–∏–Ω)
		'bradycardia_threshold': 50,  # –ø–æ—Ä–æ–≥ –±—Ä–∞–¥–∏–∫–∞—Ä–¥–∏–∏ (—É–¥/–º–∏–Ω)
		'min_consecutive_events': 10,  # –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω—ã—Ö —Å–æ–±—ã—Ç–∏–π –¥–ª—è —ç–ø–∏–∑–æ–¥–∞
		'rr_min': 0.3,  # –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π RR –∏–Ω—Ç–µ—Ä–≤–∞–ª (—Å–µ–∫)
		'rr_max': 2.0,  # –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π RR –∏–Ω—Ç–µ—Ä–≤–∞–ª (—Å–µ–∫)
		'hr_min': 40,  # –º–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –ß–°–° (—É–¥/–º–∏–Ω)
		'hr_max': 150,  # –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –ß–°–° (—É–¥/–º–∏–Ω)
	},

	# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –¥—ã—Ö–∞—Ç–µ–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
	'respiration': {
		'min_rate': 8,  # –º–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —á–∞—Å—Ç–æ—Ç–∞ –¥—ã—Ö–∞–Ω–∏—è (–¥—ã—Ö/–º–∏–Ω)
		'max_rate': 25,  # –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è —á–∞—Å—Ç–æ—Ç–∞ –¥—ã—Ö–∞–Ω–∏—è (–¥—ã—Ö/–º–∏–Ω)
		'filter_low': 0.1,  # –Ω–∏–∂–Ω—è—è –≥—Ä–∞–Ω–∏—Ü–∞ —Ñ–∏–ª—å—Ç—Ä–∞ (–ì—Ü)
		'filter_high': 1.0,  # –≤–µ—Ä—Ö–Ω—è—è –≥—Ä–∞–Ω–∏—Ü–∞ —Ñ–∏–ª—å—Ç—Ä–∞ (–ì—Ü)
		'min_segment_length': 30,  # –º–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ —Å–µ–≥–º–µ–Ω—Ç–∞ (—Å–µ–∫)
	},

	# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ SpO2 –∞–Ω–∞–ª–∏–∑–∞
	'spo2': {
		'min_valid': 75,  # –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –≤–∞–ª–∏–¥–Ω–æ–µ SpO2 (%)
		'max_valid': 100,  # –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –≤–∞–ª–∏–¥–Ω–æ–µ SpO2 (%)
		'threshold_90': 90,  # –ø–æ—Ä–æ–≥ –¥–ª—è –≤—Ä–µ–º–µ–Ω–∏ <90% —Å–∞—Ç—É—Ä–∞—Ü–∏–∏
		'threshold_85': 85,  # –ø–æ—Ä–æ–≥ –¥–ª—è –≤—Ä–µ–º–µ–Ω–∏ <85% —Å–∞—Ç—É—Ä–∞—Ü–∏–∏
	},

	# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ —Å–Ω–∞
	'sleep_quality': {
		'efficiency_weights': {85: 25, 70: 20, 50: 10},
		'n3_threshold': 15,  # –ø–æ—Ä–æ–≥ –¥–ª—è –≥–ª—É–±–æ–∫–æ–≥–æ —Å–Ω–∞ (%)
		'rem_threshold': 20,  # –ø–æ—Ä–æ–≥ –¥–ª—è REM —Å–Ω–∞ (%)
		'ahi_weights': {5: 30, 15: 20, 30: 10},
		'arousal_weights': {10: 15, 20: 10},
	}
}

class SleepAnalyzer:
	"""–û—Å–Ω–æ–≤–Ω–æ–π –∫–ª–∞—Å—Å –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Å–Ω–∞"""

	def __init__(self, config=None):
		self.config = config or ANALYSIS_CONFIG
		self.raw = None
		self.stages = None

	def load_edf_file(self, edf_path):
		"""–ó–∞–≥—Ä—É–∑–∫–∞ EDF —Ñ–∞–π–ª–∞"""
		try:
			self.raw = mne.io.read_raw_edf(edf_path, preload=True, verbose=False)
			return self.raw
		except Exception as e:
			print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Ñ–∞–π–ª–∞: {e}")
			return None

	def extract_patient_info_from_edf(self, edf_path):
		"""–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ UUID –∏–∑ EDF —Ñ–∞–π–ª–∞"""
		try:
			with open(edf_path, 'rb') as f:
				header = f.read(256).decode('latin-1', errors='ignore')
				patient_info = header[8:168].strip()

				uuid_pattern = r'([a-fA-F0-9]{8}-[a-fA-F0-9]{4}-[a-fA-F0-9]{4}-[a-fA-F0-9]{4}-[a-fA-F0-9]{12})'
				uuid_match = re.search(uuid_pattern, patient_info)

				if uuid_match:
					return {'uuid': uuid_match.group(1)}

				return {'uuid': None}

		except Exception as e:
			print(f"‚ùå –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è EDF —Ñ–∞–π–ª–∞: {e}")
			return {'uuid': None}

	def calculate_sleep_stages(self):
		"""–†–∞—Å—á–µ—Ç —Å—Ç–∞–¥–∏–π —Å–Ω–∞ –ø–æ 30-—Å–µ–∫—É–Ω–¥–Ω—ã–º —ç–ø–æ—Ö–∞–º"""
		if not self.raw or not hasattr(self.raw, 'annotations'):
			return None

		annotations = self.raw.annotations

		stage_mapping = {
			'Sleep stage W(eventUnknown)': 'Wake',
			'Sleep stage 1(eventUnknown)': 'N1',
			'Sleep stage 2(eventUnknown)': 'N2',
			'Sleep stage 3(eventUnknown)': 'N3',
			'Sleep stage R(eventUnknown)': 'REM'
		}

		stages = {stage: {'count': 0, 'minutes': 0} for stage in ['Wake', 'N1', 'N2', 'N3', 'REM']}

		for desc, duration in zip(annotations.description, annotations.duration):
			desc_str = str(desc)
			if desc_str in stage_mapping and abs(duration - 30) < 1:
				stage = stage_mapping[desc_str]
				stages[stage]['count'] += 1
				stages[stage]['minutes'] += 0.5

		self.stages = stages
		return stages

	def calculate_rem_quality(self):
		"""–†–∞—Å—á–µ—Ç –∫–∞—á–µ—Å—Ç–≤–∞ REM-—Å–Ω–∞"""
		if not self.raw or not hasattr(self.raw, 'annotations'):
			return None

		annotations = self.raw.annotations

		rem_epochs = sum(1 for desc, duration in zip(annotations.description, annotations.duration)
		                 if str(desc) == 'Sleep stage R(eventUnknown)' and abs(duration - 30) < 1)

		rem_events = sum(1 for desc in annotations.description
		                 if str(desc) == '–ë–î–ì(pointPolySomnographyREM)')

		rem_minutes = rem_epochs * 0.5
		rem_density = rem_events / rem_minutes if rem_minutes > 0 else 0

		time_score = 40 if rem_minutes >= 15 else 20 if rem_minutes >= 5 else 0
		density_score = 60 if rem_density >= 1.5 else 30 if rem_density >= 0.5 else 0
		quality_score = min(time_score + density_score, 100)

		status = ("–æ—Ç–ª–∏—á–Ω–æ" if quality_score >= 80 else
		          "—Ö–æ—Ä–æ—à–æ" if quality_score >= 60 else
		          "—É–¥–æ–≤–ª–µ—Ç–≤–æ—Ä–∏—Ç–µ–ª—å–Ω–æ" if quality_score >= 40 else "–Ω–∏–∑–∫–æ–µ")

		return {
			'rem_quality_score': int(quality_score),
			'rem_minutes': rem_minutes,
			'rem_events': rem_events,
			'rem_density': rem_density,
			'status': status
		}

	def calculate_sleep_efficiency(self):
		"""–†–∞—Å—á–µ—Ç —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ —Å–Ω–∞"""
		if not self.stages:
			return None

		total_sleep_time = sum(self.stages[stage]['minutes'] for stage in ['N1', 'N2', 'N3', 'REM'])
		total_bed_time = sum(stage['minutes'] for stage in self.stages.values())

		sleep_efficiency = (total_sleep_time / total_bed_time * 100) if total_bed_time > 0 else 0

		return {
			'sleep_efficiency': sleep_efficiency,
			'total_sleep_time': total_sleep_time,
			'total_bed_time': total_bed_time,
			'wake_after_sleep_onset': self.stages['Wake']['minutes']
		}

	def calculate_sleep_latencies(self):
		"""–†–∞—Å—á–µ—Ç —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –ª–∞—Ç–µ–Ω—Ç–Ω–æ—Å—Ç–µ–π"""
		annotations = self.raw.annotations

		sleep_onset_latency = None
		rem_latency = None

		first_sleep_epoch = None
		first_rem_epoch = None

		current_time = 0
		for desc, duration in zip(annotations.description, annotations.duration):
			desc_str = str(desc)

			if desc_str in ['Sleep stage 1(eventUnknown)', 'Sleep stage 2(eventUnknown)',
			                'Sleep stage 3(eventUnknown)', 'Sleep stage R(eventUnknown)']:
				if first_sleep_epoch is None and abs(duration - 30) < 1:
					first_sleep_epoch = current_time

			if desc_str == 'Sleep stage R(eventUnknown)' and first_rem_epoch is None and abs(duration - 30) < 1:
				first_rem_epoch = current_time

			current_time += duration

		return {
			'sleep_onset_latency': first_sleep_epoch / 60 if first_sleep_epoch else None,
			'rem_latency': (first_rem_epoch - first_sleep_epoch) / 60 if first_sleep_epoch and first_rem_epoch else None
		}

	def calculate_sleep_architecture(self):
		"""–ê–Ω–∞–ª–∏–∑ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã —Å–Ω–∞"""
		if not self.stages:
			return None

		total_sleep_time = sum(self.stages[stage]['minutes'] for stage in ['N1', 'N2', 'N3', 'REM'])

		if total_sleep_time == 0:
			return None

		architecture = {
			'n1_percentage': (self.stages['N1']['minutes'] / total_sleep_time) * 100,
			'n2_percentage': (self.stages['N2']['minutes'] / total_sleep_time) * 100,
			'n3_percentage': (self.stages['N3']['minutes'] / total_sleep_time) * 100,
			'rem_percentage': (self.stages['REM']['minutes'] / total_sleep_time) * 100,
			'deep_sleep_ratio': self.stages['N3']['minutes'] / total_sleep_time,
			'rem_nrem_ratio': self.stages['REM']['minutes'] / (
					self.stages['N1']['minutes'] + self.stages['N2']['minutes'] + self.stages['N3']['minutes'])
		}

		return architecture

	def calculate_sleep_fragmentation(self):
		"""–ê–Ω–∞–ª–∏–∑ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ —Å–Ω–∞ —Å —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ–º —Ç–∏–ø–æ–≤ –¥–≤–∏–∂–µ–Ω–∏–π"""
		annotations = self.raw.annotations

		activations = sum(1 for desc in annotations.description
		                  if str(desc) == '–ê–∫—Ç–∏–≤–∞—Ü–∏—è(pointPolySomnographyActivation)')

		limb_movements = sum(1 for desc in annotations.description
		                     if str(desc) == '–î–≤–∏–∂–µ–Ω–∏–µ –∫–æ–Ω–µ—á–Ω–æ—Å—Ç–µ–π(pointPolySomnographyLegsMovements)')

		periodic_limb_movements = sum(1 for desc in annotations.description
		                              if
		                              str(desc) == '–ü–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏–µ –¥–≤–∏–∂–µ–Ω–∏—è –∫–æ–Ω–µ—á–Ω–æ—Å—Ç–µ–π(pointPolySomnographyPeriodicalLegsMovements)')

		# –î–û–ë–ê–í–õ–ï–ù–û: –ü–æ–¥—Å—á–µ—Ç –±—Ä—É–∫—Å–∏–∑–º–æ–≤
		bruxism_events = sum(1 for desc in annotations.description
		                     if str(desc) == '–ë—Ä—É–∫—Å–∏–∑–º(pointBruxism)')

		total_sleep_time = sum(self.stages[stage]['minutes'] for stage in ['N1', 'N2', 'N3', 'REM'])

		total_movements = limb_movements + periodic_limb_movements
		fragmentation_index = (activations + total_movements) / (total_sleep_time / 60) if total_sleep_time > 0 else 0

		return {
			'fragmentation_index': fragmentation_index,
			'activations': activations,
			'limb_movements': limb_movements,
			'periodic_limb_movements': periodic_limb_movements,
			'bruxism_events': bruxism_events,  # –î–û–ë–ê–í–õ–ï–ù–û
			'total_limb_movements': total_movements,
			'arousal_index': activations / (total_sleep_time / 60) if total_sleep_time > 0 else 0
		}

	def calculate_sleep_indices(self):
		"""–†–∞—Å—á–µ—Ç —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –∏–Ω–¥–µ–∫—Å–æ–≤"""
		if not self.raw or not self.stages:
			return {}

		respiratory_events = self.calculate_respiratory_events() or {}
		total_sleep_time = sum(self.stages[stage]['minutes'] for stage in ['N1', 'N2', 'N3', 'REM'])

		if total_sleep_time == 0:
			return {}

		ahi = (respiratory_events.get('apneas', 0) + respiratory_events.get('hypopneas', 0)) / (total_sleep_time / 60)
		odi = respiratory_events.get('desaturations', 0) / (total_sleep_time / 60)
		snoring_index = respiratory_events.get('snoring', 0) / (total_sleep_time / 60)

		ahi_severity = ("–Ω–æ—Ä–º–∞" if ahi < 5 else
		                "–ª–µ–≥–∫–∞—è" if ahi < 15 else
		                "—Å—Ä–µ–¥–Ω—è—è" if ahi < 30 else "—Ç—è–∂–µ–ª–∞—è")

		return {
			'ahi': ahi,
			'ahi_severity': ahi_severity,
			'odi': odi,
			'snoring_index': snoring_index,
			'total_apneas': respiratory_events.get('apneas', 0),
			'total_hypopneas': respiratory_events.get('hypopneas', 0),
			'total_desaturations': respiratory_events.get('desaturations', 0),
			'total_snores': respiratory_events.get('snoring', 0)
		}

	def calculate_respiratory_events(self):
		"""–ê–Ω–∞–ª–∏–∑ –¥—ã—Ö–∞—Ç–µ–ª—å–Ω—ã—Ö –Ω–∞—Ä—É—à–µ–Ω–∏–π"""
		annotations = self.raw.annotations

		respiratory_events = {
			'apneas': 0,
			'hypopneas': 0,
			'desaturations': 0,
			'snoring': 0
		}

		event_mapping = {
			'–û–±—Å—Ç—Ä—É–∫—Ç–∏–≤–Ω–æ–µ –∞–ø–Ω–æ—ç(pointPolySomnographyObstructiveApnea)': 'apneas',
			'–û–±—Å—Ç—Ä—É–∫—Ç–∏–≤–Ω–æ–µ –≥–∏–ø–æ–ø–Ω–æ—ç(pointPolySomnographyHypopnea)': 'hypopneas',
			'–î–µ—Å–∞—Ç—É—Ä–∞—Ü–∏—è(pointPolySomnographyDesaturation)': 'desaturations',
			'–•—Ä–∞–ø(pointPolySomnographySnore)': 'snoring'
		}

		for desc in annotations.description:
			desc_str = str(desc)
			if desc_str in event_mapping:
				respiratory_events[event_mapping[desc_str]] += 1

		return respiratory_events

	def calculate_rem_cycles(self):
		"""–†–∞—Å—á–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ REM-—Ü–∏–∫–ª–æ–≤ –∑–∞ –Ω–æ—á—å"""
		if not self.raw or not hasattr(self.raw, 'annotations'):
			return 0

		annotations = self.raw.annotations

		stage_mapping = {
			'Sleep stage W(eventUnknown)': 'W',
			'Sleep stage 1(eventUnknown)': 'N1',
			'Sleep stage 2(eventUnknown)': 'N2',
			'Sleep stage 3(eventUnknown)': 'N3',
			'Sleep stage R(eventUnknown)': 'R'
		}

		stages_sequence = []
		current_time = 0

		for desc, duration in zip(annotations.description, annotations.duration):
			desc_str = str(desc)
			if desc_str in stage_mapping and abs(duration - 30) < 1:
				stages_sequence.append(stage_mapping[desc_str])

		if not stages_sequence:
			return 0

		rem_cycles = 0
		in_rem_cycle = False
		rem_cycle_started = False

		for i in range(1, len(stages_sequence) - 1):
			current_stage = stages_sequence[i]
			prev_stage = stages_sequence[i - 1]
			next_stage = stages_sequence[i + 1]

			if current_stage == 'R' and prev_stage in ['N1', 'N2', 'N3'] and not rem_cycle_started:
				rem_cycle_started = True
				in_rem_cycle = True

			elif current_stage == 'R' and next_stage in ['N1', 'N2', 'N3'] and in_rem_cycle:
				rem_cycles += 1
				in_rem_cycle = False
				rem_cycle_started = False

			elif current_stage == 'W' and in_rem_cycle:
				in_rem_cycle = False
				rem_cycle_started = False

		return rem_cycles

	def calculate_overall_sleep_quality(self):
		"""–ö–æ–º–ø–ª–µ–∫—Å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ —Å–Ω–∞"""
		if not self.raw or not self.stages:
			return {}

		efficiency_data = self.calculate_sleep_efficiency() or {}
		architecture_data = self.calculate_sleep_architecture() or {}
		sleep_indices = self.calculate_sleep_indices() or {}
		fragmentation_data = self.calculate_sleep_fragmentation() or {}
		rem_quality = self.calculate_rem_quality() or {}
		hr_stats = self.analyze_heart_rate_comprehensive() or {}
		rem_cycles = self.calculate_rem_cycles()

		score = 0
		cfg = self.config['sleep_quality']

		# –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å —Å–Ω–∞
		efficiency = efficiency_data.get('sleep_efficiency', 0)
		for threshold, points in cfg['efficiency_weights'].items():
			if efficiency >= threshold:
				score += points
				break

		# –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ —Å–Ω–∞
		n3_percentage = architecture_data.get('n3_percentage', 0)
		rem_percentage = architecture_data.get('rem_percentage', 0)

		if n3_percentage >= cfg['n3_threshold']:
			score += 15
		if rem_percentage >= cfg['rem_threshold']:
			score += 15

		# –î—ã—Ö–∞—Ç–µ–ª—å–Ω—ã–µ –Ω–∞—Ä—É—à–µ–Ω–∏—è
		ahi = sleep_indices.get('ahi', 0)
		for threshold, points in cfg['ahi_weights'].items():
			if ahi < threshold:
				score += points
				break

		# –§—Ä–∞–≥–º–µ–Ω—Ç–∞—Ü–∏—è
		arousal_index = fragmentation_data.get('arousal_index', 0)
		for threshold, points in cfg['arousal_weights'].items():
			if arousal_index < threshold:
				score += points
				break

		# REM –∫–∞—á–µ—Å—Ç–≤–æ
		rem_score = rem_quality.get('rem_quality_score', 0)
		score += rem_score * 0.15

		# –®—Ç—Ä–∞—Ñ –∑–∞ —Ç–∞—Ö–∏–∫–∞—Ä–¥–∏—é
		tachycardia_events = hr_stats.get('tachycardia_events', 0)
		if tachycardia_events > 10:
			score -= 15
		elif tachycardia_events > 5:
			score -= 10
		elif tachycardia_events > 0:
			score -= 5

		# –ë–æ–Ω—É—Å –∑–∞ —Ö–æ—Ä–æ—à—É—é –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É REM-—Ü–∏–∫–ª–æ–≤
		if rem_cycles >= 4:
			score += 10
		elif rem_cycles >= 3:
			score += 5

		overall_score = min(score, 100)

		if overall_score >= 85:
			status = "–æ—Ç–ª–∏—á–Ω–æ–µ"
		elif overall_score >= 70:
			status = "—Ö–æ—Ä–æ—à–µ–µ"
		elif overall_score >= 50:
			status = "—É–¥–æ–≤–ª–µ—Ç–≤–æ—Ä–∏—Ç–µ–ª—å–Ω–æ–µ"
		else:
			status = "–ø–ª–æ—Ö–æ–µ"

		return {
			'overall_score': int(overall_score),
			'status': status
		}

	def get_artifact_masks(self, artifact_marker='–ê—Ä—Ç–µ—Ñ–∞–∫—Ç(blockArtefact)'):
		"""–°–æ–∑–¥–∞–Ω–∏–µ –º–∞—Å–æ–∫ –¥–ª—è –∏—Å–∫–ª—é—á–µ–Ω–∏—è —É—á–∞—Å—Ç–∫–æ–≤ —Å –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–∞–º–∏"""
		if not self.raw or not hasattr(self.raw, 'annotations'):
			return None, None

		annotations = self.raw.annotations
		sfreq = self.raw.info['sfreq']
		total_samples = len(self.raw.times)

		valid_mask = np.ones(total_samples, dtype=bool)
		current_time = 0
		artifact_regions = []

		for desc, duration, onset in zip(annotations.description, annotations.duration, annotations.onset):
			desc_str = str(desc)

			if artifact_marker in desc_str:
				start_sample = int(onset * sfreq)
				end_sample = int((onset + duration) * sfreq)
				end_sample = min(end_sample, total_samples - 1)

				if start_sample < total_samples:
					valid_mask[start_sample:end_sample] = False
					artifact_regions.append({
						'start_time': onset,
						'end_time': onset + duration,
						'start_sample': start_sample,
						'end_sample': end_sample,
						'duration': duration
					})

		return valid_mask, artifact_regions

	def analyze_heart_rate_comprehensive(self):
		"""–ö–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Å–µ—Ä–¥–µ—á–Ω–æ–≥–æ —Ä–∏—Ç–º–∞ –∏–∑ –≠–ö–ì"""
		results = {
			'avg_heart_rate': None,
			'min_heart_rate': None,
			'max_heart_rate': None,
			'heart_rate_variability': None,
			'artifact_regions_excluded': 0,
			'tachycardia_events': 0,
			'bradycardia_events': 0,
			'analysis_method': 'ecg'
		}

		try:
			ecg_keywords = ['ecg', 'ekg', 'electrocardiogram', '—ç–∫–≥', '–∫–∞—Ä–¥–∏–æ–≥—Ä–∞–º–º–∞']
			ecg_channels = [
				ch for ch in self.raw.ch_names
				if any(keyword in ch.lower() for keyword in ecg_keywords)
			]

			if not ecg_channels:
				return self._analyze_heart_rate_from_markers()

			ecg_ch = ecg_channels[0]
			ecg_idx = self.raw.ch_names.index(ecg_ch)
			sfreq = self.raw.info['sfreq']
			max_samples = len(self.raw.times)

			data, times = self.raw[ecg_idx, :max_samples]
			if len(data) == 0:
				return self._analyze_heart_rate_from_markers()

			ecg_signal = data[0]

			artifact_mask, artifact_regions = self.get_artifact_masks()
			r_peaks = self._get_clean_r_peaks(ecg_signal, sfreq, artifact_mask, artifact_regions, max_samples)
			results['artifact_regions_excluded'] = len(artifact_regions)

			if len(r_peaks) <= 100:
				return self._analyze_heart_rate_from_markers()

			rr_intervals, heart_rates = self._calculate_heart_rate_metrics(r_peaks, sfreq)

			if len(heart_rates) > 5:
				results.update(self._calculate_basic_stats(heart_rates, rr_intervals))
				results.update(self._detect_heart_rate_episodes(heart_rates))

			else:
				results = self._analyze_heart_rate_from_markers()

		except Exception as e:
			print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∫–æ–º–ø–ª–µ–∫—Å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –≠–ö–ì: {e}")
			results = self._analyze_heart_rate_from_markers()

		return results

	def _get_clean_r_peaks(self, ecg_signal, sfreq, artifact_mask, artifact_regions, max_samples):
		"""–û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ R-–ø–∏–∫–æ–≤ —Å –∏—Å–∫–ª—é—á–µ–Ω–∏–µ–º –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤"""
		if artifact_mask is not None and len(artifact_mask) >= max_samples:
			segment_mask = artifact_mask[:max_samples]
			valid_segments = self.find_continuous_segments(segment_mask, min_segment_length=int(sfreq * 10))

			all_r_peaks = []
			for start, end in valid_segments:
				segment_ecg = ecg_signal[start:end]
				if len(segment_ecg) > int(sfreq * 5):
					segment_peaks = self.detect_r_peaks(segment_ecg, sfreq)
					segment_peaks += start
					all_r_peaks.extend(segment_peaks)

			return np.array(all_r_peaks)
		else:
			return self.detect_r_peaks(ecg_signal, sfreq)

	def _calculate_heart_rate_metrics(self, r_peaks, sfreq):
		"""–†–∞—Å—á–µ—Ç RR-–∏–Ω—Ç–µ—Ä–≤–∞–ª–æ–≤ –∏ –ß–°–° —Å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π"""
		cfg = self.config['ecg']
		rr_intervals = np.diff(r_peaks) / sfreq

		valid_rr_mask = (rr_intervals > cfg['rr_min']) & (rr_intervals < cfg['rr_max'])
		valid_rr = rr_intervals[valid_rr_mask]

		if len(valid_rr) > 1:
			heart_rates = 60.0 / valid_rr
			valid_hr_mask = (heart_rates >= cfg['hr_min']) & (heart_rates <= cfg['hr_max'])
			valid_hr = heart_rates[valid_hr_mask]
			return valid_rr, valid_hr

		return np.array([]), np.array([])

	def _calculate_basic_stats(self, heart_rates, rr_intervals):
		"""–†–∞—Å—á–µ—Ç –±–∞–∑–æ–≤—ã—Ö —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫ –ß–°–°"""
		return {
			'avg_heart_rate': round(float(np.median(heart_rates)), 2),
			'min_heart_rate': round(float(np.percentile(heart_rates, 5)), 2),
			'max_heart_rate': round(float(np.percentile(heart_rates, 95)), 2),
			'heart_rate_variability': round(float(np.std(rr_intervals * 1000)), 2)
		}

	def _detect_heart_rate_episodes(self, heart_rates):
		"""–û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ —ç–ø–∏–∑–æ–¥–æ–≤ —Ç–∞—Ö–∏–∫–∞—Ä–¥–∏–∏ –∏ –±—Ä–∞–¥–∏–∫–∞—Ä–¥–∏–∏"""
		cfg = self.config['ecg']
		episodes = {
			'tachycardia_events': 0,
			'bradycardia_events': 0
		}

		tachy_count = 0
		brady_count = 0
		tachy_episode = False
		brady_episode = False

		for hr in heart_rates:
			# –¢–∞—Ö–∏–∫–∞—Ä–¥–∏—è
			if hr > cfg['tachycardia_threshold']:
				tachy_count += 1
				if tachy_count >= cfg['min_consecutive_events'] and not tachy_episode:
					episodes['tachycardia_events'] += 1
					tachy_episode = True
			else:
				tachy_count = 0
				tachy_episode = False

			# –ë—Ä–∞–¥–∏–∫–∞—Ä–¥–∏—è
			if hr < cfg['bradycardia_threshold']:
				brady_count += 1
				if brady_count >= cfg['min_consecutive_events'] and not brady_episode:
					episodes['bradycardia_events'] += 1
					brady_episode = True
			else:
				brady_count = 0
				brady_episode = False

		return episodes

	def _analyze_heart_rate_from_markers(self):
		"""–†–µ–∑–µ—Ä–≤–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –ø–æ –º–∞—Ä–∫–µ—Ä–∞–º –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π"""
		results = {
			'avg_heart_rate': None,
			'min_heart_rate': None,
			'max_heart_rate': None,
			'heart_rate_variability': None,
			'artifact_regions_excluded': 0,
			'tachycardia_events': 0,
			'bradycardia_events': 0,
			'analysis_method': 'markers'
		}

		try:
			annotations = self.raw.annotations
			for desc in annotations.description:
				desc_str = str(desc)
				if '–¢–∞—Ö–∏–∫–∞—Ä–¥–∏—è' in desc_str:
					results['tachycardia_events'] += 1
				elif '–ë—Ä–∞–¥–∏–∫–∞—Ä–¥–∏—è' in desc_str:
					results['bradycardia_events'] += 1
		except Exception as e:
			print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –ø–æ –º–∞—Ä–∫–µ—Ä–∞–º: {e}")

		return results

	def find_continuous_segments(self, mask, min_segment_length=1):
		"""–ù–∞—Ö–æ–¥–∏—Ç –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω—ã–µ —Å–µ–≥–º–µ–Ω—Ç—ã –≤ –º–∞—Å–∫–µ"""
		segments = []
		start = None

		for i, value in enumerate(mask):
			if value and start is None:
				start = i
			elif not value and start is not None:
				if i - start >= min_segment_length:
					segments.append((start, i))
				start = None

		if start is not None and len(mask) - start >= min_segment_length:
			segments.append((start, len(mask)))

		return segments

	def detect_r_peaks(self, ecg_signal, sfreq):
		"""–î–µ—Ç–µ–∫—Ü–∏—è R-–∑—É–±—Ü–æ–≤ –≤ –≠–ö–ì —Å–∏–≥–Ω–∞–ª–µ —Å –∞–¥–∞–ø—Ç–∏–≤–Ω—ã–º –ø–æ—Ä–æ–≥–æ–º"""
		try:
			ecg_clean = ecg_signal - np.median(ecg_signal)

			if len(ecg_clean) > 100:
				b, a = signal.butter(3, [5 / (sfreq / 2), 35 / (sfreq / 2)], btype='band')
				ecg_filtered = signal.filtfilt(b, a, ecg_clean)
			else:
				ecg_filtered = ecg_clean

			ecg_squared = np.square(ecg_filtered)
			window_size = int(0.12 * sfreq)
			if window_size % 2 == 0:
				window_size += 1
			ecg_smoothed = signal.medfilt(ecg_squared, kernel_size=window_size)

			# 3. –ê–î–ê–ü–¢–ò–í–ù–´–ô –ü–û–†–û–ì –î–õ–Ø –î–ò–ù–ê–ú–ò–ß–ï–°–ö–ò–• –ò–ó–ú–ï–ù–ï–ù–ò–ô
			window_size_adaptive = 5 * sfreq  # 5-—Å–µ–∫—É–Ω–¥–Ω–æ–µ –æ–∫–Ω–æ
			overlap = window_size_adaptive // 2  # 50% –ø–µ—Ä–µ–∫—Ä—ã—Ç–∏–µ

			adaptive_thresholds = np.zeros_like(ecg_smoothed)

			for i in range(0, len(ecg_smoothed), overlap):
				end_idx = min(i + window_size_adaptive, len(ecg_smoothed))
				window = ecg_smoothed[i:end_idx]

				if len(window) > 0:
					# –ò—Å–ø–æ–ª—å–∑—É–µ–º 85-–π –ø—Ä–æ—Ü–µ–Ω—Ç–∏–ª—å –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –æ–∫–Ω–∞
					window_threshold = np.percentile(window, 85)
					# –ó–∞–ø–æ–ª–Ω—è–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–π —Å–µ–≥–º–µ–Ω—Ç —ç—Ç–∏–º –ø–æ—Ä–æ–≥–æ–º
					adaptive_thresholds[i:end_idx] = window_threshold

			# –ï—Å–ª–∏ –º–∞—Å—Å–∏–≤ —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π –¥–ª—è —Å–∫–æ–ª—å–∑—è—â–µ–≥–æ –æ–∫–Ω–∞, –∏—Å–ø–æ–ª—å–∑—É–µ–º –≥–ª–æ–±–∞–ª—å–Ω—ã–π –ø–æ—Ä–æ–≥
			if len(ecg_smoothed) < window_size_adaptive:
				adaptive_thresholds[:] = np.percentile(ecg_smoothed, 85)

			# –ü–æ–∏—Å–∫ –ø–∏–∫–æ–≤ —Å –∞–¥–∞–ø—Ç–∏–≤–Ω—ã–º –ø–æ—Ä–æ–≥–æ–º
			peaks = []
			for i in range(len(ecg_smoothed)):
				# –ù–∞—Ö–æ–¥–∏–º –ø–∏–∫–∏, –ø—Ä–µ–≤—ã—à–∞—é—â–∏–µ –ª–æ–∫–∞–ª—å–Ω—ã–π –ø–æ—Ä–æ–≥
				if (ecg_smoothed[i] > adaptive_thresholds[i] and
						(i == 0 or ecg_smoothed[i] > ecg_smoothed[i - 1]) and
						(i == len(ecg_smoothed) - 1 or ecg_smoothed[i] > ecg_smoothed[i + 1])):

					# –ü—Ä–æ–≤–µ—Ä—è–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –æ—Ç –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ –ø–∏–∫–∞
					if len(peaks) == 0 or (i - peaks[-1]) >= int(0.3 * sfreq):
						peaks.append(i)

			peaks = np.array(peaks)

			# –í–ê–õ–ò–î–ê–¶–ò–Ø –ù–ê–ô–î–ï–ù–ù–´–• –ü–ò–ö–û–í (–¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ)
			if len(peaks) > 0:
				valid_peaks = []
				for peak in peaks:
					# –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –∞–º–ø–ª–∏—Ç—É–¥–∞ –≤ –∏—Å—Ö–æ–¥–Ω–æ–º —Å–∏–≥–Ω–∞–ª–µ –∑–Ω–∞—á–∏–º–∞
					if (ecg_signal[peak] > np.median(ecg_signal) + 0.1 * np.std(ecg_signal)):
						valid_peaks.append(peak)
				peaks = np.array(valid_peaks)

			return peaks

		except Exception as e:
			print(f"–û—à–∏–±–∫–∞ –≤ –¥–µ—Ç–µ–∫—Ü–∏–∏ R-–ø–∏–∫–æ–≤: {e}")
			return np.array([])

	def analyze_spo2_channel_fast(self):
		"""–ë—ã—Å—Ç—Ä—ã–π –∞–Ω–∞–ª–∏–∑ SpO2 —Å –∏—Å–∫–ª—é—á–µ–Ω–∏–µ–º –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤"""
		spo2_stats = {
			'avg_spo2': None, 'min_spo2': None,
			'time_below_spo2_90': 0, 'time_below_spo2_85': 0,
			'spo2_baseline': None,
			'artifact_regions_excluded': 0
		}

		try:
			artifact_mask, artifact_regions = self.get_artifact_masks()
			cfg = self.config['spo2']

			spo2_channels = [ch for ch in self.raw.ch_names if any(x in ch.lower() for x in ['spo2', 'sao2', 'sat'])]
			if spo2_channels:
				spo2_idx = self.raw.ch_names.index(spo2_channels[0])
				data, times = self.raw[spo2_idx, :]
				if len(data) > 0:
					spo2_values = data[0]

					if artifact_mask is not None:
						valid_spo2 = spo2_values[(spo2_values >= cfg['min_valid']) &
						                         (spo2_values <= cfg['max_valid']) & artifact_mask]
						spo2_stats['artifact_regions_excluded'] = len(artifact_regions)
					else:
						valid_spo2 = spo2_values[(spo2_values >= cfg['min_valid']) &
						                         (spo2_values <= cfg['max_valid'])]

					if len(valid_spo2) > 0:
						spo2_stats['avg_spo2'] = round(float(np.median(valid_spo2)), 1)
						spo2_stats['min_spo2'] = round(float(np.percentile(valid_spo2, 1)), 1)
						spo2_stats['spo2_baseline'] = round(float(np.percentile(valid_spo2, 90)), 1)

						if artifact_mask is not None:
							total_valid_samples = np.sum(artifact_mask)
							if total_valid_samples > 0:
								samples_below_90 = np.sum(
									(spo2_values < cfg['threshold_90']) & artifact_mask &
									(spo2_values >= cfg['min_valid']) & (spo2_values <= cfg['max_valid']))
								samples_below_85 = np.sum(
									(spo2_values < cfg['threshold_85']) & artifact_mask &
									(spo2_values >= cfg['min_valid']) & (spo2_values <= cfg['max_valid']))

								total_duration_seconds = self.raw.times[-1]
								valid_duration_ratio = total_valid_samples / len(self.raw.times)

								time_below_90 = (samples_below_90 / total_valid_samples) * (
										total_duration_seconds / 60) * valid_duration_ratio
								time_below_85 = (samples_below_85 / total_valid_samples) * (
										total_duration_seconds / 60) * valid_duration_ratio

								spo2_stats['time_below_spo2_90'] = int(time_below_90)
								spo2_stats['time_below_spo2_85'] = int(time_below_85)

		except Exception as e:
			print(f"  ‚ö†Ô∏è –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ SpO2: {e}")

		return spo2_stats

	def analyze_respiratory_channels_improved(self):
		"""–£–ª—É—á—à–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –¥—ã—Ö–∞—Ç–µ–ª—å–Ω—ã—Ö –∫–∞–Ω–∞–ª–æ–≤"""
		resp_stats = {
			'avg_resp_rate': None,
			'min_resp_rate': None,
			'max_resp_rate': None,
			'signal_quality': 'unknown'
		}

		try:
			resp_patterns = ['resp', 'breath', '–¥—ã—Ö–∞–Ω–∏–µ', 'thorax', 'chest', 'abdomen', 'flow']
			resp_channels = [
				ch for ch in self.raw.ch_names
				if any(pattern in ch.lower() for pattern in resp_patterns)
			]

			if not resp_channels:
				resp_stats['signal_quality'] = 'no_channel'
				return resp_stats

			best_rates = []
			for resp_ch in resp_channels[:2]:
				rates = self.analyze_single_resp_channel(resp_ch)
				if rates:
					best_rates.extend(rates)

			if not best_rates:
				resp_stats['signal_quality'] = 'no_signal'
				return resp_stats

			cfg = self.config['respiration']
			valid_rates = [r for r in best_rates if cfg['min_rate'] <= r <= cfg['max_rate']]

			if len(valid_rates) < 5:
				valid_rates = [r for r in best_rates if 6 <= r <= 30]

			if not valid_rates:
				resp_stats['signal_quality'] = 'invalid_rates'
				return resp_stats

			valid_rates = np.array(valid_rates)
			q1, q3 = np.percentile(valid_rates, [25, 75])
			iqr = q3 - q1
			lower_bound = q1 - 1.5 * iqr
			upper_bound = q3 + 1.5 * iqr

			final_rates = valid_rates[(valid_rates >= lower_bound) & (valid_rates <= upper_bound)]

			if len(final_rates) < 3:
				final_rates = valid_rates

			resp_stats['avg_resp_rate'] = round(float(np.median(final_rates)), 1)
			resp_stats['min_resp_rate'] = round(float(np.percentile(final_rates, 10)), 1)
			resp_stats['max_resp_rate'] = round(float(np.percentile(final_rates, 90)), 1)
			resp_stats['signal_quality'] = 'good' if len(final_rates) >= 10 else 'moderate'

		except Exception as e:
			print(f"  ‚ö†Ô∏è –û—à–∏–±–∫–∞ —É–ª—É—á—à–µ–Ω–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –¥—ã—Ö–∞–Ω–∏—è: {e}")
			resp_stats['signal_quality'] = 'error'

		return resp_stats

	def analyze_single_resp_channel(self, channel_name):
		"""–ê–Ω–∞–ª–∏–∑ –æ–¥–Ω–æ–≥–æ –¥—ã—Ö–∞—Ç–µ–ª—å–Ω–æ–≥–æ –∫–∞–Ω–∞–ª–∞ —Å –∏—Å–∫–ª—é—á–µ–Ω–∏–µ–º –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤"""
		try:
			artifact_mask, artifact_regions = self.get_artifact_masks()
			channel_idx = self.raw.ch_names.index(channel_name)
			sfreq = self.raw.info['sfreq']
			cfg = self.config['respiration']

			max_samples = len(self.raw.times)
			data, times = self.raw[channel_idx, :max_samples]

			if len(data) == 0:
				return []

			resp_signal = data[0]

			if artifact_mask is not None and len(artifact_mask) >= max_samples:
				segment_mask = artifact_mask[:max_samples]
				valid_segments = self.find_continuous_segments(segment_mask,
				                                               min_segment_length=int(
					                                               sfreq * cfg['min_segment_length']))

				breathing_rates = []
				for start, end in valid_segments:
					segment_signal = resp_signal[start:end]
					if len(segment_signal) > int(sfreq * cfg['min_segment_length']):
						resp_clean = self.preprocess_resp_signal(segment_signal, sfreq)
						if resp_clean is not None:
							rate_peaks = self.analyze_breathing_peaks_improved(resp_clean, sfreq)
							if rate_peaks is not None and len(rate_peaks) > 0:  # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ None –∏ –¥–ª–∏–Ω—É
								breathing_rates.extend(rate_peaks)  # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –∏—Å–ø–æ–ª—å–∑—É–µ–º extend –≤–º–µ—Å—Ç–æ append

				if breathing_rates:
					return breathing_rates

			# –ï—Å–ª–∏ –Ω–µ—Ç –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤ –∏–ª–∏ –ø–æ—Å–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤ –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö
			resp_clean = self.preprocess_resp_signal(resp_signal, sfreq)
			if resp_clean is not None:
				rate_peaks = self.analyze_breathing_peaks_improved(resp_clean, sfreq)
				return rate_peaks if rate_peaks is not None else []  # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ None

		except Exception as e:
			print(f"    ‚ö†Ô∏è –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –∫–∞–Ω–∞–ª–∞ {channel_name}: {e}")

		return []

	def analyze_breathing_peaks_improved(self, resp_signal, sfreq):
		"""–£–ª—É—á—à–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –¥—ã—Ö–∞—Ç–µ–ª—å–Ω—ã—Ö –ø–∏–∫–æ–≤"""
		try:
			# –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –∏—Å–ø–æ–ª—å–∑—É–µ–º –±–æ–ª–µ–µ –ø—Ä–æ—Å—Ç–æ–π –ø–æ–¥—Ö–æ–¥ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –¥—ã—Ö–∞–Ω–∏—è
			resp_normalized = (resp_signal - np.mean(resp_signal)) / (np.std(resp_signal) + 1e-8)

			# –ü–æ–∏—Å–∫ –ø–∏–∫–æ–≤ –≤ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–º —Å–∏–≥–Ω–∞–ª–µ
			peaks, properties = signal.find_peaks(
				resp_normalized,
				distance=int(1.0 * sfreq),  # –º–∏–Ω–∏–º—É–º 1 —Å–µ–∫—É–Ω–¥–∞ –º–µ–∂–¥—É –≤–¥–æ—Ö–∞–º–∏
				prominence=0.3,
				height=0.2
			)

			if len(peaks) < 4:
				return []

			# –†–∞—Å—á–µ—Ç –∏–Ω—Ç–µ—Ä–≤–∞–ª–æ–≤ –º–µ–∂–¥—É –≤–¥–æ—Ö–∞–º–∏
			breath_intervals = np.diff(peaks) / sfreq

			# –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã—Ö –∏–Ω—Ç–µ—Ä–≤–∞–ª–æ–≤ (1.0-7.5 —Å–µ–∫ = 8-60 –¥—ã—Ö/–º–∏–Ω)
			valid_intervals = breath_intervals[
				(breath_intervals >= 1.0) & (breath_intervals <= 7.5)
				]

			if len(valid_intervals) < 3:
				return []

			# –†–∞—Å—á–µ—Ç —á–∞—Å—Ç–æ—Ç—ã –¥—ã—Ö–∞–Ω–∏—è
			breathing_rates = 60.0 / valid_intervals

			# –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è —á–∞—Å—Ç–æ—Ç
			valid_rates = breathing_rates[
				(breathing_rates >= 8) & (breathing_rates <= 25)
				]

			return valid_rates.tolist() if len(valid_rates) > 0 else []

		except Exception as e:
			print(f"      ‚ö†Ô∏è –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –¥—ã—Ö–∞—Ç–µ–ª—å–Ω—ã—Ö –ø–∏–∫–æ–≤: {e}")
			return []

	def preprocess_resp_signal(self, resp_signal, sfreq):
		"""–ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥—ã—Ö–∞—Ç–µ–ª—å–Ω–æ–≥–æ —Å–∏–≥–Ω–∞–ª–∞"""
		try:
			resp_clean = resp_signal - np.median(resp_signal)
			cfg = self.config['respiration']
			b, a = signal.butter(3, [cfg['filter_low'] / (sfreq / 2), cfg['filter_high'] / (sfreq / 2)], btype='band')
			resp_filtered = signal.filtfilt(b, a, resp_clean)
			return resp_filtered
		except Exception as e:
			return None

	def export_minimal_hypnogram(self):
		"""–≠–∫—Å–ø–æ—Ä—Ç –≥–∏–ø–Ω–æ–≥—Ä–∞–º–º—ã –≤ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ –¥–ª—è SQL"""
		if not self.raw or not hasattr(self.raw, 'annotations'):
			return None

		annotations = self.raw.annotations

		stage_mapping = {
			'Sleep stage W(eventUnknown)': 'W',
			'Sleep stage 1(eventUnknown)': '1',
			'Sleep stage 2(eventUnknown)': '2',
			'Sleep stage 3(eventUnknown)': '3',
			'Sleep stage R(eventUnknown)': 'R'
		}

		# –°–æ–±–∏—Ä–∞–µ–º —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Å—Ç–∞–¥–∏–π
		stages_sequence = []

		for desc, duration in zip(annotations.description, annotations.duration):
			desc_str = str(desc)
			if desc_str in stage_mapping and abs(duration - 30) < 1:
				stages_sequence.append(stage_mapping[desc_str])

		# –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–∞–Ω–Ω—ã—Ö
		minimal_data = {
			'e': len(stages_sequence),  # epochs
			'd': 30,  # duration per epoch
			's': stages_sequence  # stages
		}

		return minimal_data

	def print_annotation_statistics(self):
		"""–í—ã–≤–æ–¥ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π –≤ –ø–æ—Ä—è–¥–∫–µ —É–±—ã–≤–∞–Ω–∏—è –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞"""
		if not self.raw or not hasattr(self.raw, 'annotations'):
			print("‚ùå –ù–µ—Ç –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")
			return

		annotations = self.raw.annotations
		annotation_counts = Counter(str(desc) for desc in annotations.description)

		print("\nüìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ê–ù–ù–û–¢–ê–¶–ò–ô")
		print("=" * 50)
		print(f"–í—Å–µ–≥–æ –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π: {len(annotations)}")
		print(f"–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Ç–∏–ø–æ–≤: {len(annotation_counts)}")
		print("\n–¢–∏–ø—ã –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π (–ø–æ —É–±—ã–≤–∞–Ω–∏—é):")

		for desc, count in sorted(annotation_counts.items(), key=lambda x: x[1], reverse=True):
			print(f"  {count:>5} √ó {desc}")

	def generate_sql_insert_statements(self, edf_path, patient_info):
		"""–ì–µ–Ω–µ—Ä–∞—Ü–∏—è SQL UPDATE –∑–∞–ø—Ä–æ—Å–æ–≤ –≤ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ"""
		if not self.raw:
			return None

		# –û—Å–Ω–æ–≤–Ω—ã–µ —Ä–∞—Å—á–µ—Ç—ã
		stages = self.calculate_sleep_stages() or {}
		efficiency = self.calculate_sleep_efficiency() or {}
		hypnogram_data = self.export_minimal_hypnogram()
		total_sleep_time = efficiency.get('total_sleep_time', 0)
		architecture = self.calculate_sleep_architecture() or {}
		fragmentation = self.calculate_sleep_fragmentation() or {}
		respiratory_events = self.calculate_respiratory_events() or {}
		sleep_indices = self.calculate_sleep_indices() or {}
		rem_quality = self.calculate_rem_quality() or {}
		hr_stats = self.analyze_heart_rate_comprehensive() or {}
		spo2_stats = self.analyze_spo2_channel_fast() or {}
		resp_stats = self.analyze_respiratory_channels_improved() or {}
		latencies = self.calculate_sleep_latencies() or {}
		overall_quality = self.calculate_overall_sleep_quality() or {}
		rem_cycles = self.calculate_rem_cycles()

		# –†–∞—Å—á–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤
		artifact_mask, artifact_regions = self.get_artifact_masks()
		artifact_count = len(artifact_regions) if artifact_regions else 0
		artifact_duration_minutes = sum(
			region['duration'] for region in artifact_regions) / 60 if artifact_regions else 0

		# –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è SQL UPDATE
		sql_data = {
			# –û–±—â–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã —Å–Ω–∞
			'total_sleep_time': int(efficiency.get('total_sleep_time', 0)),
			'total_bed_time': int(efficiency.get('total_bed_time', 0)),
			'sleep_efficiency': round(efficiency.get('sleep_efficiency', 0), 2),
			'sleep_latency': int(latencies.get('sleep_onset_latency', 0)) if latencies.get(
				'sleep_onset_latency') else 0,
			'wake_after_sleep_onset': int(efficiency.get('wake_after_sleep_onset', 0)),

			# –°—Ç–∞–¥–∏–∏ —Å–Ω–∞ (–º–∏–Ω—É—Ç—ã)
			'n1_minutes': int(stages['N1']['minutes']) if stages else 0,
			'n2_minutes': int(stages['N2']['minutes']) if stages else 0,
			'n3_minutes': int(stages['N3']['minutes']) if stages else 0,
			'rem_minutes': int(stages['REM']['minutes']) if stages else 0,

			# –°—Ç–∞–¥–∏–∏ —Å–Ω–∞ (–ø—Ä–æ—Ü–µ–Ω—Ç—ã)
			'n1_percentage': round(architecture.get('n1_percentage', 0), 2),
			'n2_percentage': round(architecture.get('n2_percentage', 0), 2),
			'n3_percentage': round(architecture.get('n3_percentage', 0), 2),
			'rem_percentage': round(architecture.get('rem_percentage', 0), 2),

			# REM-—Å–æ–Ω
			'rem_latency': int(latencies.get('rem_latency')) if latencies.get('rem_latency') else None,
			'rem_epochs': stages['REM']['count'] if stages else None,
			'rem_cycles': rem_cycles,
			'rem_events': rem_quality.get('rem_events'),
			'rem_density': round(rem_quality.get('rem_density', 0), 2) if rem_quality.get('rem_density') else None,
			'rem_quality_score': rem_quality.get('rem_quality_score'),

			# –î—ã—Ö–∞—Ç–µ–ª—å–Ω—ã–µ –Ω–∞—Ä—É—à–µ–Ω–∏—è (—Å–æ–±—ã—Ç–∏—è)
			'total_apneas': respiratory_events.get('apneas', 0),
			'obstructive_apneas': respiratory_events.get('apneas', 0),
			'central_apneas': 0,  # –¢—Ä–µ–±—É–µ—Ç –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
			'mixed_apneas': 0,  # –¢—Ä–µ–±—É–µ—Ç –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
			'total_hypopneas': respiratory_events.get('hypopneas', 0),
			'total_desaturations': respiratory_events.get('desaturations', 0),
			'total_snores': respiratory_events.get('snoring', 0),

			# –î—ã—Ö–∞—Ç–µ–ª—å–Ω—ã–µ –∏–Ω–¥–µ–∫—Å—ã
			'ahi': round(sleep_indices.get('ahi', 0), 2),
			'ahi_obstructive': round(sleep_indices.get('ahi', 0), 2),
			'ahi_central': 0,  # –¢—Ä–µ–±—É–µ—Ç –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
			'odi': round(sleep_indices.get('odi', 0), 2),
			'snore_index': round(sleep_indices.get('snoring_index', 0), 2),

			# –°–∞—Ç—É—Ä–∞—Ü–∏—è –∫–∏—Å–ª–æ—Ä–æ–¥–∞
			'avg_spo2': spo2_stats.get('avg_spo2'),
			'min_spo2': spo2_stats.get('min_spo2'),
			'spo2_baseline': spo2_stats.get('spo2_baseline'),
			'time_below_spo2_90': spo2_stats.get('time_below_spo2_90', 0),
			'time_below_spo2_85': spo2_stats.get('time_below_spo2_85', 0),

			# –°–µ—Ä–¥–µ—á–Ω—ã–π —Ä–∏—Ç–º
			'avg_heart_rate': hr_stats.get('avg_heart_rate'),
			'min_heart_rate': hr_stats.get('min_heart_rate'),
			'max_heart_rate': hr_stats.get('max_heart_rate'),
			'heart_rate_variability': hr_stats.get('heart_rate_variability'),
			'tachycardia_events': hr_stats.get('tachycardia_events'),
			'bradycardia_events': hr_stats.get('bradycardia_events'),

			# –î—ã—Ö–∞—Ç–µ–ª—å–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞
			'avg_resp_rate': resp_stats.get('avg_resp_rate'),
			'min_resp_rate': resp_stats.get('min_resp_rate'),
			'max_resp_rate': resp_stats.get('max_resp_rate'),

			# –î–≤–∏–≥–∞—Ç–µ–ª—å–Ω—ã–µ –Ω–∞—Ä—É—à–µ–Ω–∏—è
			'total_limb_movements': fragmentation.get('total_limb_movements', 0),
			'periodic_limb_movements': fragmentation.get('periodic_limb_movements', 0),
			'plmi': round(fragmentation.get('periodic_limb_movements', 0) / (total_sleep_time / 60),
			              2) if total_sleep_time > 0 else 0,
			'bruxism_events': fragmentation.get('bruxism_events', 0),

			# –ê–∫—Ç–∏–≤–∞—Ü–∏–∏ –∏ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞—Ü–∏—è
			'total_arousals': fragmentation.get('activations', 0),
			'arousal_index': round(fragmentation.get('arousal_index', 0), 2),
			'sleep_fragmentation_index': round(fragmentation.get('fragmentation_index', 0), 2),

			# –û–±—â–∞—è –æ—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ —Å–Ω–∞
			'overall_sleep_quality': overall_quality.get('overall_score'),
			'sleep_quality_status': overall_quality.get('status'),
			'hypnogram_data': json.dumps(hypnogram_data) if hypnogram_data else None,

			# –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
			'data_quality': 'good',
			'analysis_notes': f"–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ —Ñ–∞–π–ª–∞: {os.path.basename(edf_path)}",
			'calculated_at': 'NOW()'
		}

		# –ì–µ–Ω–µ—Ä–∞—Ü–∏—è SQL UPDATE –∑–∞–ø—Ä–æ—Å–∞ –¥–ª—è sleep_statistics
		set_parts = []
		for key, value in sql_data.items():
			if key == 'calculated_at':
				set_parts.append(f"`{key}` = {value}")
			elif value is None:
				set_parts.append(f"`{key}` = NULL")
			elif isinstance(value, str):
				# –≠–∫—Ä–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–∞–≤—ã—á–µ–∫ –≤ —Å—Ç—Ä–æ–∫–∞—Ö
				escaped_value = value.replace("'", "''")
				set_parts.append(f"`{key}` = '{escaped_value}'")
			else:
				set_parts.append(f"`{key}` = {value}")

		# –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø–æ–ª–Ω–æ–≥–æ SQL
		uuid = patient_info.get('uuid', 'unknown')
		sql = f"""-- SQL –∑–∞–ø—Ä–æ—Å –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ —Å–Ω–∞
	-- UUID –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è: {uuid}
	-- –§–∞–π–ª: {os.path.basename(edf_path)}
	-- –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

	-- –í–ê–ñ–ù–û: –≠—Ç–∞ –∑–∞–ø–∏—Å—å –¥–æ–ª–∂–Ω–∞ –≤—ã–ø–æ–ª–Ω—è—Ç—å—Å—è –ü–û–°–õ–ï –∏–º–ø–æ—Ä—Ç–∞ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è —á–µ—Ä–µ–∑ –ø—Ä–æ—Ü–µ–¥—É—Ä—É
	-- –ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –¥–æ–ª–∂–Ω–æ —É–∂–µ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞—Ç—å –≤ —Ç–∞–±–ª–∏—Ü–∞—Ö psg_studies –∏ sleep_statistics

	-- –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ —Å–Ω–∞
	UPDATE `sleep_statistics` ss
	JOIN `psg_studies` ps ON ss.study_id = ps.study_id
	SET {', '.join(set_parts)}
	WHERE ps.edf_uuid = '{uuid}';

	-- –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ–± –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–∞—Ö –≤ psg_studies
	UPDATE `psg_studies` 
	SET `artifact_count` = {artifact_count}, 
	    `artifact_duration_minutes` = {round(artifact_duration_minutes, 2)}
	WHERE `edf_uuid` = '{uuid}';"""

		# –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ —Ñ–∞–π–ª
		sql_filename = f"sleep_stats_{uuid}.sql"
		try:
			with open(sql_filename, 'w', encoding='utf-8') as f:
				f.write(sql + "\n")

			print(f"‚úÖ SQL —Ñ–∞–π–ª —Å–æ–∑–¥–∞–Ω: {sql_filename}")
			print(f"üìä UUID –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è: {uuid}")
			print(f"üìù –¢–∏–ø –∑–∞–ø—Ä–æ—Å–∞: UPDATE (–æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–π –∑–∞–ø–∏—Å–∏)")
			print(f"üö´ –ê—Ä—Ç–µ—Ñ–∞–∫—Ç—ã: {artifact_count} —Ä–µ–≥–∏–æ–Ω–æ–≤, {round(artifact_duration_minutes, 2)} –º–∏–Ω—É—Ç")

			return sql_filename

		except Exception as e:
			print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è SQL —Ñ–∞–π–ª–∞: {e}")
			return None

	def process_edf_folder(self, folder_path, output_folder="sql_output"):
		"""–ü–∞–∫–µ—Ç–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –≤—Å–µ—Ö EDF —Ñ–∞–π–ª–æ–≤ –≤ –ø–∞–ø–∫–µ"""
		import glob

		# –°–æ–∑–¥–∞–Ω–∏–µ –ø–∞–ø–∫–∏ –¥–ª—è –≤—ã—Ö–æ–¥–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
		os.makedirs(output_folder, exist_ok=True)

		# –ü–æ–∏—Å–∫ –≤—Å–µ—Ö EDF —Ñ–∞–π–ª–æ–≤ –≤ –ø–∞–ø–∫–µ
		edf_files = glob.glob(os.path.join(folder_path, "*.edf"))

		if not edf_files:
			print(f"‚ùå –í –ø–∞–ø–∫–µ {folder_path} –Ω–µ –Ω–∞–π–¥–µ–Ω–æ EDF —Ñ–∞–π–ª–æ–≤")
			return []

		print(f"üìÅ –ù–∞–π–¥–µ–Ω–æ {len(edf_files)} EDF —Ñ–∞–π–ª–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏")

		processed_files = []
		failed_files = []

		for i, edf_path in enumerate(edf_files, 1):
			print(f"\n{'=' * 60}")
			print(f"üîç –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–∞ {i}/{len(edf_files)}: {os.path.basename(edf_path)}")
			print(f"{'=' * 60}")

			try:
				# –ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–∞
				raw = self.load_edf_file(edf_path)
				if not raw:
					print(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —Ñ–∞–π–ª: {os.path.basename(edf_path)}")
					failed_files.append(edf_path)
					continue

				# –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –ø–∞—Ü–∏–µ–Ω—Ç–µ
				patient_info = self.extract_patient_info_from_edf(edf_path)

				# –ì–µ–Ω–µ—Ä–∞—Ü–∏—è SQL
				sql_filename = self.generate_sql_insert_statements(edf_path, patient_info)

				if sql_filename:
					# –ü–µ—Ä–µ–º–µ—â–µ–Ω–∏–µ SQL —Ñ–∞–π–ª–∞ –≤ –≤—ã—Ö–æ–¥–Ω—É—é –ø–∞–ø–∫—É
					new_sql_path = os.path.join(output_folder, os.path.basename(sql_filename))
					os.rename(sql_filename, new_sql_path)
					processed_files.append(new_sql_path)

					print(f"‚úÖ –£—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω: {os.path.basename(edf_path)}")
					print(f"üìÑ SQL —Ñ–∞–π–ª: {os.path.basename(new_sql_path)}")
				else:
					print(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å SQL –¥–ª—è: {os.path.basename(edf_path)}")
					failed_files.append(edf_path)

			except Exception as e:
				print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ {os.path.basename(edf_path)}: {e}")
				failed_files.append(edf_path)

		# –°–≤–æ–¥–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏
		print(f"\n{'=' * 60}")
		print("üìä –°–í–û–î–ö–ê –û–ë–†–ê–ë–û–¢–ö–ò")
		print(f"{'=' * 60}")
		print(f"‚úÖ –£—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {len(processed_files)} —Ñ–∞–π–ª–æ–≤")
		print(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å: {len(failed_files)} —Ñ–∞–π–ª–æ–≤")

		if processed_files:
			print(f"\nüìÅ SQL —Ñ–∞–π–ª—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ –ø–∞–ø–∫–µ: {output_folder}")
			for file in processed_files:
				print(f"  ‚Ä¢ {os.path.basename(file)}")

		if failed_files:
			print(f"\nüö´ –§–∞–π–ª—ã —Å –æ—à–∏–±–∫–∞–º–∏:")
			for file in failed_files:
				print(f"  ‚Ä¢ {os.path.basename(file)}")

		return processed_files

def main():
	"""–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏ —Ä–∞–±–æ—Ç—ã"""
	analyzer = SleepAnalyzer()

	# –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
	# edf_path = "EDF/test2.edf"
	# raw = analyzer.load_edf_file(edf_path)
	# if raw:
	#     analyzer.print_annotation_statistics()
	#     patient_info = analyzer.extract_patient_info_from_edf(edf_path)
	#     sql_filename = analyzer.generate_sql_insert_statements(edf_path, patient_info)

	# –ü–∞–∫–µ—Ç–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –≤—Å–µ—Ö —Ñ–∞–π–ª–æ–≤ –≤ –ø–∞–ø–∫–µ
	folder_path = "EDF"  # –∑–∞–º–µ–Ω–∏—Ç–µ –Ω–∞ –≤–∞—à—É –ø–∞–ø–∫—É
	processed_files = analyzer.process_edf_folder(folder_path)

	if processed_files:
		print(f"\nüéâ –ü–∞–∫–µ—Ç–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞! –°–æ–∑–¥–∞–Ω–æ {len(processed_files)} SQL —Ñ–∞–π–ª–æ–≤")

if __name__ == "__main__":
	main()